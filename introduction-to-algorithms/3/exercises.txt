3.1-1
Let's rewrite as theta definition:
c1 * (f(n) + g(n)) <= max(f(n),g(n)) <= c2 * (f(n) + g(n))
Let's suppose that f(n) is max, we get:
c1 * (f(n) + g(n)) <= f(n) <= c2 * (f(n) + g(n))
and divide by the function:
c1 * (1 + g(n)/f(n) <= 1 <= c2 * (1 + g(n)/f(n))
since f(n) > g(n), g(n)/f(n) < 1. Let's replace it with upper bound 1
2*c1 <= 1 <= 2*c2
So if c1 <= 0.5 and c2 >= 0.5 that satisfy the theta notation.

3.1-2
Let's rewrite as theta definition:
c1 * n^b <= (n + a)^b <= c2 * n^b
the middle of the formula can be transformed to binomial theorem:
(n+a)^b = k1 * n^b + k2 * n^(b-1) ... + kb * a^b
if we divide the inequality on n^b and when n goes to infinity we get:
c1 <= k1 <= c2 ,where k1 is the first binomial koef and we get:
c1 <= 1 <= c2, so the constants are c1 <=1, c2 >=1

3.1-3
Because O(f(n)) is an upper bound of the running time.
It says about the worst-case running time.

3.1-4
2^(n+1) <= c * 2n => 2 <= c
2^2n <= c* 2^n  => 2^n <=c
=> so incorrect cause for any constant c when n goes to infinity 2^n will eventually become bigger

3.1-5
(proved on paper)

3.1-7
we have
0 <= f1(n) < c1 g(n) - for little o
0 <=  c2 g(n) < f2(n) - for little omega
=> f1(n)/c1 < g(n) < f2(n)/c2.
choosing n0 = max(n01,n02), for n > n0 the intersection of two sets is indeed emtpy set.

3.1-8
(given on paper)

==========================
3.2-1
initial:
f(n) >= f(m), n >= m
g(n) >= g(m), n >= m

- summing them we got f(n) + g(n) >= f(m) + g(m), for n >= m
- f(g(n)): given g(n) >= g(m) when n >= m => we got f(g(n)) >= f(g(n)) when n>=m
- f(n)*g(n):  when n >= m we multiple bigger numbers (positive), so f(n) * g(n) >= f(m) * g(m) when n >= m

3.2-1
a^(log_b(c))=c^(log_b(a));
c^(log_b(a))=c^(log_c(a)/log_c(b))
=c^(log_c(a)*(log_c(b))^-1)=
=(c^(log_c(a)))^((log_c(b))^-1)=a^(log_b(c))

see http://asciimath.org/

